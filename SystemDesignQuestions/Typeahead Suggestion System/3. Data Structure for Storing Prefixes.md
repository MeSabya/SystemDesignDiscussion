# Data Structure for Storing Prefixes
Our system should suggest â€œUNIVERSALâ€ and â€œUNIVERSITYâ€ when the user types â€œUNIV.â€

The trie (pronounced â€œtryâ€) is one of the data structures thatâ€™s best suited to our needs. A trie is a tree-like data structure for storing phrases, with each tree node storing a character in the phrase in order. If we needed to store UNITED, UNIQUE, UNIVERSAL, and UNIVERSITY in the trie, it would look like this:

![image](https://user-images.githubusercontent.com/33947539/203198483-d5a7dbf3-7753-4539-ba78-524ed1907d46.png)

![image](https://user-images.githubusercontent.com/33947539/203198889-9bbc1031-f239-421c-a013-5218f7c82dcf.png)

The trie can combine nodes as one where only a single branch exists, which reduces the depth of the tree. This also reduces the traversal time, which in turn increases the efficiency. As an example, a space- and time-efficient model of the above trie is the following:

![image](https://user-images.githubusercontent.com/33947539/203199006-7148b260-2a24-4f3b-ad8f-549cc9f77a0b.png)

## Track the top searches
Since our system keeps track of the top searches and returns the top suggestion, we store the number of times each term is searched in the trie node. Letâ€™s say that a user searches for UNITED 15 times, UNIQUE 20 times, UNIVERSAL 21 times, and UNIVERSITY 25 times. In order to provide the top suggestions to the user, these counts are stored in each node where these terms terminate. The resultant trie looks like this:

![image](https://user-images.githubusercontent.com/33947539/203199375-86b07787-69f5-4a86-9021-f9d4830f5a0c.png)

If a user types â€œUNI,â€ the system starts traversing the tree under the root node for UNI. After comparing all the terms originating from the root node, the system provides suggestions of all the possible words. Since the frequency of the word UNIVERSITY is high, it appears at the top. Similarly, the frequency of the word UNITED is relatively low, so it appears last. If the user picks UNIQUE from the list of suggestions, the number against UNIQUE increases to 21.

ğŸ‘‰ ***We reduced the time to traverse the trie by combining nodes with single branches and reducing the number of levels. Is there any other way to minimize the trie traversal time?***

One way to reduce the trie traversal time is to pre-compute and save the top ten (or any number of our choosing) suggestions for every prefix in the node. This means that instead of traversing the trie each time a user types in â€œUNIVERSâ€ into the search box, the system will have precomputed, sorted, and stored the solution to the prefix UNIVERSâ€”that is, UNIVERSITY, UNIVERSAL, and so onâ€”inside the node that carries the prefix UNIVERS. However, this approach requires extra space to save precomputed results.

![image](https://user-images.githubusercontent.com/33947539/203199614-3054469a-9b2b-4d71-825f-dd3f70f551ba.png)

## Trie partitioning

We aim to design a system like Google that we can use to handle billions of queries every second. One server isnâ€™t sufficient to handle such an enormous amount of requests. In addition to this, storing all the prefixes in a single trie isnâ€™t a viable option for the systemâ€™s availability, scalability, and durability. A good solution is to split the trie into multiple tries for a better user experience.

Letâ€™s assume that the trie is split into two parts, and each part has a replica for durability purposes. All the prefixes starting from â€œAâ€ to â€œMâ€ are stored on Server/01, and the replica is stored on Server/02. Similarly, all the prefixes starting from â€œNâ€ to â€œZâ€ are stored on Server/03, and the replica is stored on Server/04. It should be noted that this simple technique doesnâ€™t always balance the load equally because some prefixes have many more words while others have fewer. We use this simple technique to understand partitioning.

We can split the trie into as many parts as we wish to distribute the load on to different servers and achieve the desired performance.

![image](https://user-images.githubusercontent.com/33947539/203200956-4e070b8a-14fe-4079-8460-15f4f295921f.png)

ğŸ‘‰ ***Where will the mapping between the prefixes and their primary and secondary storage be stored? Who will manage and direct the requests to these servers?***

In a distributed system where multiple clusters consisting of several servers can be used for a specific service, we use a cluster manager like ZooKeeper to store the mapping between clusters.

## Update the trie

Billions of searches every day give us hundreds of thousands of queries per second. Therefore, the process of updating a trie for every query is highly resource intensive and time-consuming and could hamper our read requests. This issue can be resolved by updating the trie offline after a specific interval. To update the trie offline, we log the queries and their frequency in a hash table and aggregate the data at regular intervals. After a specific amount of time, the trie is updated with the aggregated information. After the update of the trie, all the previous entries are deleted from the hash table.

![image](https://user-images.githubusercontent.com/33947539/203202933-f5625401-9cc0-4bd5-bbc8-2b307f0849b6.png)

We can put up a MapReduce (MR) job to process all of the logging data regularly, letâ€™s say every 15 minutes. These MR services calculate the frequency of all the searched phrases in the previous 15 minutes and dump the results into a hash table in a database like Cassandra. After that, we may further update the trie with the new data. We can update the current copy of the trie with all of the new words and their frequencies. We should perform this offline because our priority is to provide suggestions to users instead of keeping them waiting.

Primarily, we can update the trie using the following two approaches.

We can replicate the trie on each server to update it offline. After that, we can start using it for suggestions and throw away the old ones.
Another way is to have one primary copy and several secondary copies of the trie. While the main copy is used to answer the queries, we may update the secondary copy. We may also make the secondary our main copy once the upgrade is complete. We can then upgrade our previous primary, which will then be able to serve the traffic as well.

ğŸ‘‰ ***If the prefix frequencies keep increasing over time, the corresponding integers storing them can overflow. How can we manage this issue?***

We can normalize frequencies by mapping them in a range, letâ€™s say between zero and 1,000. Alternatively, we can stop any further additions after a certain threshold is reached, assuming that any prefix reaching that threshold is at the top of the rankings.


