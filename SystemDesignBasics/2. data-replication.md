Copying the same data over multiple nodes in distributed systems is critical to keep the database up and keep on serving queries even during faults.
Following are other reason behind data replication in a distributed system :

## Why do we need it?

Letâ€™s say If I am the CEO of some e-commerce startup based in the USA. Now I want to cater to orders globally like from people living in Antarctica :P But my servers are running in the USA. So when a user comes to my application and searches an item it gets a lot of time to display the final results on his browser. I donâ€™t think increasing resources on my server is going to solve this problem. Isnâ€™t it?
So whatâ€™s the root cause of the problem here?

ðŸ‘‰ Yes, You got it right. itâ€™s a **network latency issue**. 

So by replication, we can keep data close to the userâ€™s geographic area to reduce latency. 
Similar things are done by Netflix and Amazon prime video etc thatâ€™s why you people can watch HD movies without any buffering delays.

Similarly, other problems which replication caters are :
 
          ðŸ‘‰ **Availability & Fault toleration issues**

          ðŸ‘‰ **Data throughput issues**

Letâ€™s again consider a real-time scenario. So as a CEO of an e-commerce startup, if my application goes down (Unavailable) then my whole business could get impacted and I could have lost thousands of bucks and can lose the trust of our customers which is very bad these days. Hence we need better **Fault tolerance** in our system.

Even if my startup gets very much popular like Amazon etc then my server would be handling millions of transactions/queries per second (TPS/QPS). And if my system is not that much scalable then user experience would be deteriorated. The quality of service (QOS) will be very poor. No one would like to visit our application.
Hence we need to make our system more Scalable and need to have better Data throughput.

## How does replication work?
There are three ways through which leaders replicate data to its follower :
1. Statement-based replication
2. Write-Ahead log
3. Row-based replication

### Statement-based replication
In this strategy leader logs every write statement(INSERT/UPDATE/DELETE) that it executes and sends the same to its follower and then the follower executes it on its node.
#### Drawback :
Any non-deterministic function can result in different writes on follower and leader(Like RAND() or NOW() functions). 

### Write-Ahead log
Whenever a query comes to a system, even before executing that query, 
it is written in an append-only log file also known as Write-ahead log file. This log file can be used to replicate data to follower nodes.
PostgreSQL and Oracle employ this strategy of data replication.

### Row-based replication
A row-based replication involves a sequence of records describing writes to the level of row. For example, an insertion of row contains information 
about all new values of columns. A delete contains information to identify rows to be deleted and an update contains new values of all columns.

**Approaches to data replication**
- Single leader
- Multi leader
- leaderless

## Single leader replication (Active-Passive or Master-Slave Replication)
- So in leader based architecture, client (application server) requests are sent to **leader DB first** and after that leader sends the data changes to all of its followers as a   part of the replication log.

- Whenever a client wants to read data from the database then it can query either leader or any of the follower (Yes there is generally more than just one follower to make the 
  system highly available). However, writes to the database is only accepted on the leader by the client.
  
- Now whenever a follower dies our application will not get impacted as there is not just a single node of data. Our application can read from other followers as well and hence   this makes our system highly Read Scalable
- Used in: PostgreSQL, MySql, SQL Server, MongoDB, Kafka, etc.

### Points to Ponder over ðŸ¤”

ðŸ¤”One of the crucial points you might be thinking is that what if there is a delay in replicating data from leader to follower and a client reads from a follower?

Yes, there is a high possibility for this scenario to occur but stale reads are acceptable and this is inevitable because as per the CAP Theorem  you can achieve only two guarantees out of Consistency, Partition Tolerance, Availability at a time. Which means stale reads are acceptable. This is known as Eventual-Consistency. Even read-heavy systems like Facebook or Instagram are eventually consistent.

***Replication strategies in Master-Slave Replication***
        1. Synchronous replication
        2. Asynchronous replication

### Synchronous replication strategy in Master-slave architecture
- In this strategy, followers are guaranteed to have an up to date copy of data (Strong Consistency) which is an advantage.

- But one of the biggest disadvantages it has is that it will block the client until the leader receives the OK response from all the followers. Now if you have a very high read scalable system like Facebook with thousands of followers nodes then waiting for data to be replicated at each node is not a good user experience.

### Asynchronous replication strategy in Master-slave architecture

- This strategy will not block the user/client for the response when they want to write data to the leader but yes it comes with the caveat of eventual consistency.
- One disadvantage I can think of this strategy right now is that if by some issue followers arenâ€™t accepting changes from the leader (might be network problem) then any new    
  writes by the client will be lost if the leader itself goes down. Hence writes are not Durable sometimes which is a trade-off in this strategy.

## Handling Node outages in replication  
So there are two scenarios as mentioned below:
    
    Follower failure
    Leader failure
    
**Follower failure**

So in the scenario of follower failure, we can use a strategy called **Catchup recovery**. 
In this strategy, the follower (which got disconnected) can connect to the leader again and request all data changes that occur when the follower was disconnected.

**Leader failure**

Now in the scenario of Leader failure, we can use a strategy called **Failover**. In this strategy, One of the followers needs to be promoted as a new leader.

ðŸ‘‰***Now you people might be wondering which follower to make the leader? How is it decided?***

So yes there is a voting algorithm which is called **Consensus Algorithm**. 
In layman terms, in this algorithm, we have Quorum of followers and all the followers decide which follower should be made a leader.  
  

## Multi-Leader Replication

### Issues in Leader based Replication

Letâ€™s take a real-time scenario to understand the issue in Leader based Replication.
Again I will extend my previous blog example here. So as the CEO of an e-commerce startup based in the USA, I wanted to cater to orders from people living in Antarctica :P
No issues, as a solution what I can do is to place some of my database servers (Followers) in Antarctica itself to reduce the Read Latency of my application (As customers are equivalent to God :P) but there is a limitation here. Take some time and think about it.

Yes, you guessed it correct what about **Write Latency**.

So as we know in leader based replication all writes must go through the leader itself and there is only a single leader in it.
Now I have two options, whether to place my leader in the data center of Antarctica or to place my leader in the data center of the USA (near the headquarters).
So, in either case, customers coming to place orders (Write operation for DB) from the different geographic areas are going to suffer Write Latency. Which in turn can impact the performance of my system again.
Also what if the data center having the leader (containing latest changed) fails and those changes were not replicated to all the followers in other data centers?
So are you able to see the flaws in our current implementation? Yes, I am trying to create a basic requirement to have a better solution. 

**Indeed thatâ€™s Multi-Leader Replication.**

So in Multi-Leader replication, we are going to have one leader in each of my data centers and each data centerâ€™s leader replicates its changes to the leaders in other data centers **asynchronously.**

### Advantages of Multi-Leader Replication

**Better Performance** as compared to Single leader replication as we have now reduced both Read & Write Latency of our application

**High Fault Tolerance** as each data center can continue operating independently of others if any data center goes down. This is possible because each data center has its leader. Also, replication catches up when the failed datacenter comes back online

### Multi-Leader Replication used in our daily lives

E:g Google Calendar, Outlook Calendar, Google sheets, Google docs, Microsoft Excel etc.

So when you make any change while you are offline in the calendar app like you booking a slot for the meeting.
Now those changes need to be synced (replicated) with the server (including other devices on which app is installed) when our device gets online back. So every device database can act as a dynamic leader and performs Async Multi-leader replication..

### Issues in Multi-Leader Replication with its possible solutions?

![image](https://user-images.githubusercontent.com/33947539/147865634-24117c3a-8e9f-4a9a-9702-4ec340ede8c1.png)

So by going through the above realtime implementation of Multi-Leader Replication, you people might be wondering that what if there is a conflict between the changes?

**Possible Solutions for above-mentioned problems**

    Conflict Detection
    Conflict Avoidance (Recommended approach)

##### Conflict Avoidance:

So according to this technique if the application can ensure that all writes for a particular record go through the same leader (data center), then conflicts cannot occur.
Probably that datacenter is in his geographical location or is the nearest datacenter to his geographical location.

Yes, you people might be wondering what if a user has moved to a different location and is now closer to a different datacenter. Yes, you got it right, in this situation, the conflict avoidance technique will break.







