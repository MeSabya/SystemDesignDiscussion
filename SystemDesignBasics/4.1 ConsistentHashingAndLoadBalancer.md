Where do you send the requests, If there are multiple Users?

![image](https://user-images.githubusercontent.com/33947539/148021811-3f5db665-362f-4466-b3df-5fb0e26bf72f.png)

Should the User 2 request go to Application Server 1 or Application Server 2?

At the very minimum level if you have N servers you want in general balance a load of all these servers. Now imaging all of these servers carrying a load. The requests are the things they need to process. So the server has the Load.

So the taking N servers and trying to balance the load among of all them is called Load Balancing. The concept of Hashing will help to implement this concept.

## Distribute weight using Hashing

So you want evenly distribute the weight across all servers. Assume there is a Request ID for each and every request. And RequestID you can expect uniformly random. 

When Mobile(Client) sends a request to the server it randomly generates a number(0 to m1 number). You can hash the Request ID using a hash function(h(r1)).

ðŸ‘‰ For example, a hash function can be used to map random numbers to some fixed number between 0 â€¦ m1. Given any number, it will always try to map it to any integer between 0 to m1.
Suppose m1 is 50. Then for example, for any hash function will always return a value between 0 to 50.
When you hash it you get a particular Value(m1). This Value/Number can be mapped to a particular server after getting the remainder with n servers.

![image](https://user-images.githubusercontent.com/33947539/148029018-2fd18944-5360-404e-8a55-62bf2a1ce056.png)

Here your hash function is uniformly random. You can expect all the servers to have a uniform load. So each of the servers will have
 
 >(Number of Requests)/n 
 >load and the Load Factor is 1/n.

ðŸ¤” ***what happens if we need to add more servers if the users hitting more and more requests.***

Now User 1, 2, 3, and 4 requests assign to different servers. As an example, User 1 Request ID is 44. Now the hash value is 9. Since there are 5 servers now the value of the remainder is 4. Which means that User Request goes to Application Server 4. Like this, all the Request path to servers will change.
So the cost of the change in this is high.

ðŸ¤” ***Why such a big deal?***

In practice, the Request ID is never Random or it is rarely Random. Request ID usually encapsulates some of the information of the User. For example User ID.
h(Encapsulate information with User ID) ----> m1 
If the Request ID is the same then the hash value will be the same again and again since we are using the same hashing algorithm.
m1%n ----> p
If the hash value(m1) is the same then the request going send to the same server again and again. If I am being sent to the same server again and again why should I so that all the time?. Why not store it in the local cache?

### Rehashing
Depending on the User ID we can send requests to a specific server(Ex: User 1 request should go to Server 1) and once we sent them you can store relevant information in the cache on those servers.
In the above caching mechanism what going to happen is the entire system changes all Users now need to go to different servers and 
all the useful cache information you had is going to useless because the numbers of the servers which you are serving completely changed. This is called **Rehashing.**

```
The solution is Consistent Hashing
```

## Defining Consistent Hashing

- Consistent hashing solves the problem of rehashing by providing a distribution scheme which does not directly depend on the number of servers.
- Consistent Hashing is a distributed hashing scheme that operates independently of the number of servers or objects in a distributed hash table by assigning them a position on an abstract circle, or hash ring. This allows servers and objects to scale without affecting the overall system.

>All keys and servers are hashed using the same hash function and placed on the edge of the circle. To find out which server to ask for a given key or store a given key, we need to first locate the key on the circle and move in a clockwise direction until we find a server.


#### Example1:

![image](https://user-images.githubusercontent.com/33947539/148034765-46a5456d-3bfa-442c-a720-93b2c923e9cf.png)

Now we have 5 servers. According to consistent hashing rule, User 1 is on server S1, User2 is on S3, User 3 is on S2 and User 4 is on S4 server.

Inconsistent hashing when a server is removed or added then the only key from that server is relocated. For example, if server S3 is removed then, all keys from server S3 will be moved to server S4 but keys stored on server S4, S0, S1, and S2 are not relocated. But there is one problem when server S3 is removed then keys from S3 are not equally distributed among remaining servers S0, S1, S2, and S4. They were only assigned to server S4 which will increase the load on server S4.

ðŸ‘‰ *To evenly distribute the load among servers when a server is added or removed, it creates a fixed number of replicas ( known as virtual nodes) of each server and distributed it along the circle. So instead of server labels S1, S2, S3, and S4, we will have S00 S01â€¦S09, S10 S11â€¦S19, S20 S21â€¦S29, S30 S31â€¦S39 and S40 S41â€¦S49. The factor for a number of replicas is also known as weight, depends on the situation.*

Suppose server S3 is removed, then all S3 replicas with labels S30 S31 â€¦ S39 must be removed. Now the objects keys adjacent to S3X labels will be automatically re-assigned to S4X and S2X. All keys originally assigned to S4 and S2 will not be moved.
Similar things happen if we add a server. Suppose we want to add a server S5 as a replacement of S3 then we need to add labels S50 S51 â€¦ S59. In the ideal case, one-third of keys from S4 and S2 will be reassigned to S5.

>In general, only the K/N number of keys are needed to remapped when a server is added or removed. K is the number of keys and N is the number of servers ( to be specific, maximum of the initial and final number of servers)

### Consistent hashing, in a nutshell, does this:

- Stop trying to keep one value at exactly one location. Let one location house multiple values from multiple keys.
- Donâ€™t number your locations consecutively. Give them effectively random numbers between 0 and infinity.
- Donâ€™t compute hash % number of locations. Instead, find the smallest location number greater than your keyâ€™s hash, and put it there.
- If your hash is greater than all locations, put it in the lowest-numbered location.

#### Example2:

I start with five locations randomly numbered 1, 20, 41, 1024, 2016. Given a key with hash 1013, I put it in the location numbered 1024. Given a key with hash 2017, I put it in the location numbered 1.

Why is this better? Letâ€™s see what happens when we walk through our steps:

- Start with five locations randomly numbered 1, 20, 41, 1024, 2016. Location number 1024 disappears - weâ€™re left with 1, 20, 41, 2016.
- All keys with a hash greater than 2016 are still mapped to 1. They donâ€™t need to change.
- All keys with hashes lower than 20, or 41, or 2016 are still mapped to locations 20, 41 and 2016. They donâ€™t need to change.
- Only keys with hash greater than 41 and less than 1024 need to change. The new smallest location greater than these numbers is now 2016. Thus, they just need to be remapped to 2016.

>For 2,000 keys spread across 100 locations, you now need to move only 20 keys to a new location if 1 location with only 20 keys goes down.

ðŸ‘‰ This is the main benefit of consistent hashing: you now no longer need to move so many things just because one location has disappeared.


## How to Implement A Consistent Hash Ring:

Consider our requirements:

```
We need a structure that is capable of searching for values.
We need a structure that is capable of maintaining a sorted ordering.
```

#### References:
[Consistent Hashing Implementation](https://akshatm.svbtle.com/consistent-hash-rings-theory-and-implementation)

[Consistent Hashing Theory With Load balancer](https://medium.com/swlh/load-balancing-and-consistent-hashing-5fe0156035e1)




